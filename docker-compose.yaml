name: openai-proxy

services:

  litellm:
    image: ghcr.io/berriai/litellm:main-v1.44.4
    restart: always
    volumes:
      - ./litellm-config.yaml:/app/config.yaml
    command: --port 4000 --config config.yaml
    ports:
      - 4000:4000
    env_file:
      - .env

  redis:
    image: redis:7.2.4-alpine3.19
    restart: always
    volumes:
      - redis_data:/data

  langfuse:
    image: langfuse/langfuse:2.75.2
    restart: always
    depends_on:
      db:
        condition: service_healthy
    ports:
      - 3000:3000
    environment:
      - DATABASE_URL=${LANGFUSE_DATABASE_URL:?error}
      - ENCRYPTION_KEY=${ENCRYPTION_KEY:?error}
      - NEXTAUTH_URL=http://localhost:3000
      - TELEMETRY_ENABLED=${TELEMETRY_ENABLED:-true}
      - LANGFUSE_ENABLE_EXPERIMENTAL_FEATURES=${LANGFUSE_ENABLE_EXPERIMENTAL_FEATURES:-false}
    env_file:
      - .env

  db:
    image: postgres:15.2-alpine3.17
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 3s
      timeout: 3s
      retries: 10
    environment:
      - POSTGRES_USER=${POSTGRES_USER:?error}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:?error}
      - POSTGRES_DB=${POSTGRES_DB:?error}
    ports:
      - 5432:5432
    volumes:
      - database_data:/var/lib/postgresql/data
    env_file:
      - .env

volumes:
  database_data:
    driver: local
  redis_data:
    driver: local
